{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Exercise_Autodiff_Algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qt_irrBWLLB",
        "colab_type": "text"
      },
      "source": [
        "# Automatic Differentiation Explained \n",
        "### using PyTorch and Python with Applications to Linear Regression solved using Gradient Descent\n",
        "\n",
        "In this notebook, you can learn about:\n",
        "\n",
        "* what is a tensor in deep learning\n",
        "* how are scalar and array tensors created and used in PyTorch\n",
        "* how PyTorch `autograd` framework can be used for linear regression\n",
        "* how reverse mode automatic differentiation can be implemented using Python\n",
        "* the design principles behind PyTorch `autograd` application programming interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4QWrv6rKQ04",
        "colab_type": "text"
      },
      "source": [
        "## Import the __`torch`__ package and __`matplotlib`__ for graphics.\n",
        "\n",
        "Initialize the pseudo-random number generator and report the installed version of `PyTorch`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw2yu0HIKQ05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as pt\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (15, 8)\n",
        "pt.manual_seed(42)\n",
        "pt.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdMn-cuZSsbp",
        "colab_type": "text"
      },
      "source": [
        "## Tensor is the core PyTorch data structure (container)\n",
        "\n",
        "* in deep learning, a tensor is a multi-dimensional array\n",
        "* the number of indices needed to access a value in the tensor is equal to the tensor dimension (rank)\n",
        "* the number of values along every dimension (tensor shape) is constant, in other words, you can't have a matrix with 42 columns in the 1st row and 3 columns in the 2nd row.\n",
        "\n",
        "<img height=\"480\" src=\"https://i.imgur.com/sbHDGMs.png\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtk2hwC5QPUi",
        "colab_type": "text"
      },
      "source": [
        "Let's initialize `X` as a tensor array, with values from an evenly spaced sequence of 50 numbers betweeen -5 and 5, inclusive on both ends."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJs21aQF80lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOd3o0siQ5BE",
        "colab_type": "text"
      },
      "source": [
        "Assuming that `X` holds the features for the model, lets initialize the targets using the equation: \n",
        "\n",
        "$ y = 2 * X  + \\epsilon $\n",
        "\n",
        "where $ \\epsilon $ is just normal noise. The value of `2.` is arbitrary, just to generate some sample data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0qkoBhL9GsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmO7hAeuRdEh",
        "colab_type": "text"
      },
      "source": [
        "Now you can plot a scatter graph of `X` and `y` as well as a line plot of `2 * X` without the noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NWNb6hB9XJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4BgCAPMSiLo",
        "colab_type": "text"
      },
      "source": [
        "## Solve using PyTorch `autograd` and gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ez2IlyR-x6_",
        "colab_type": "text"
      },
      "source": [
        "Initialize `w`, the model parameter to a scalar tensor with `requires_grad=True` (more on this in a moment). \n",
        "\n",
        "The value of `w` can be changed in place by sampling from a uniform distribution using `pt.nn.init.uniform_` More complex initializations like Kaiming or Xavier do not apply since `w` is just a single parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcFMmV4SYzQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kgiIT7gZVWN",
        "colab_type": "text"
      },
      "source": [
        "Define a `forward` function to return an estimate of `y` from `X` and `w` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCrqRV5QZhup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCEl3QjHZkaV",
        "colab_type": "text"
      },
      "source": [
        "Define an `mse` function to compute the mean squared error loss based on `y` and the estimate of `y`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8NDS_rkZwnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN26Fl7SZ5vR",
        "colab_type": "text"
      },
      "source": [
        "Use constant values for the gradient descent learning rate and the number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2s7jUBPaEg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzw6M7fcaK1L",
        "colab_type": "text"
      },
      "source": [
        "Repeating gradient descent for `EPOCHS` iterations should be enough to obtain a close estimate of the analytical solution to the linear regression problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a6pnaxkAFrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTfW7XiIeV-4",
        "colab_type": "text"
      },
      "source": [
        "Recall from linear algebra that the ordinary least squares solution is $ (X^TX)^{-1}X^Ty $\n",
        "\n",
        "In PyTorch `@` is the operator for matrix multiplication.\n",
        "\n",
        "**Self-check:** Why doesn't the analytical solution return `2.0`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAqpsc4-eZC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE3wdfUk83Wc",
        "colab_type": "text"
      },
      "source": [
        "## Understanding reverse mode accumulating automatic differentiation\n",
        "\n",
        "\n",
        "Automatic differentiation (autodiff) is different from:\n",
        "\n",
        "* numeric differentiation, which is based on an approximation of $   \\lim_{\\epsilon \\to 0} \\frac{f(x + \\epsilon) - f(x)}{\\epsilon}$, which can be numerically unstable at the extreme values of the differentiated functions and  accumulate small errors introduced by floating point number approximations to real numbers.\n",
        "\n",
        "* symbolic differentiation which attempts to derive a general symbolic expression of the differentiated function for arbitrary values requiring more computation and memory. \n",
        "\n",
        "Autodiff differentiates a function for specific values of the function's input variables one at a time, with a computation complexity $ O(n) $ where `n` is the number of the mathematical operations used by the differentiated function. Notice that $ O(n) $ holds only when the number of outputs of the function is fewer than the number of inputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kt9PqPRjCkw",
        "colab_type": "text"
      },
      "source": [
        "Create a `Scalar` class, a rank 0 tensor, with support for `__add__`, `__mul__`, and `__repr__` methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghW9x_7LKQ09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqeyPMtaKQ1A",
        "colab_type": "text"
      },
      "source": [
        "## Create a `Scalar` instance for `x = 2.0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdZXolFUKQ1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpCVxuQcKQ1E",
        "colab_type": "text"
      },
      "source": [
        "## Define `y = x` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu8de4X4KQ1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qq9ScpmKQ1H",
        "colab_type": "text"
      },
      "source": [
        "## Prepare for and call `backward` on `y`\n",
        "* Use floating point values\n",
        "* Zero out the accumulating gradients\n",
        "* Initialize $ \\frac{\\partial y}{ \\partial y} $\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAHVfnC_KQ1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRbBgulCKQ1L",
        "colab_type": "text"
      },
      "source": [
        "* check that $ \\frac{\\partial y}{ \\partial x} = 1.0 $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBimRd4cKQ1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC5POt4UKQ1P",
        "colab_type": "text"
      },
      "source": [
        "* **Self-check:** Why the did the implementation return the correct answer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-JVg1nkKQ1P",
        "colab_type": "text"
      },
      "source": [
        "## Implement `backward` support in the` __add__` function\n",
        "* **hint:** given $ y = x + z $, $ \\frac{\\partial y}{ \\partial x} = 1.0 $ and $ \\frac{\\partial y}{ \\partial z} = 1.0 $\n",
        "\n",
        "\n",
        "* **hint:** don't forget the recursive `backward`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALT7TH5LKQ1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoQ8FV8DKQ1S",
        "colab_type": "text"
      },
      "source": [
        "  ## Define `y = 3 * x` for `x = 3.0`\n",
        "* **hint:** recall that $ 3 * x = x + x + x $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s88Zk_6cKQ1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx3zDy3dKQ1V",
        "colab_type": "text"
      },
      "source": [
        "## Prepare for and run the backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKtdBqCIKQ1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw8otmYLKQ1Z",
        "colab_type": "text"
      },
      "source": [
        "* check that $ \\frac{\\partial y}{ \\partial x} = 3.0 $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaZsCpANKQ1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA2ggcfHKQ1c",
        "colab_type": "text"
      },
      "source": [
        "## Implement `backward` support in the` __mul__` function\n",
        "* **hint:** given $ y = c * x$, $ \\frac{\\partial y}{ \\partial x} = c $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuR5VHEBKQ1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReYBUarZKQ1f",
        "colab_type": "text"
      },
      "source": [
        "## Use `y = x^3 + 2*x` for `x = 4.0`\n",
        "* **hint:** recall that $ x^3 = x * x * x $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VnU35HOKQ1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr15Uw_cKQ1i",
        "colab_type": "text"
      },
      "source": [
        "* given $ y = x^3 + 2x $ the analytical solution to $ \\frac{\\partial y}{ \\partial x} = 3x^2+2 $\n",
        "* check that your implementation of `Scalar` returns the correct value of $ \\frac{\\partial y}{ \\partial x} $ when $ x = 4.0 $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um4aAcr9KQ1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivKVjg0tKQ1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBDfSGfcKQ1p",
        "colab_type": "text"
      },
      "source": [
        "## Apply `Scalar` to linear regression\n",
        "* set the random seed to `42`\n",
        "* randomly init the model parameter `w`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy4Phpx4KQ1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIYhatJTKQ1s",
        "colab_type": "text"
      },
      "source": [
        "## Make linear regression data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txdVmceyKQ1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF9WrMD4qqxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHnQPRuvKQ1v",
        "colab_type": "text"
      },
      "source": [
        "## Implement a `forward` function using `w`\n",
        "* **hint:** the function should return $ w * X $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rD8GNipKQ1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHeMP08VKQ1x",
        "colab_type": "text"
      },
      "source": [
        "## Implement the mean squared error calculation\n",
        "* **hint:** Python `sum` can use a starter value as the 2nd argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiW6fdXIKQ1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5qi1_frKQ1z",
        "colab_type": "text"
      },
      "source": [
        "## Confirm that gradient descent recovers the value used to generate `y` values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9ztA1u7KQ10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXjGAtiKNOIS",
        "colab_type": "text"
      },
      "source": [
        "Copyright 2020 CounterFactual.AI LLC. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ]
}